{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 300)\n"
     ]
    }
   ],
   "source": [
    "# 550 data with 300 features\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# It's a binary classification problem \n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "K-fold data partition: Implement the K-fold cross-validation function. Your function should take K as an argument and return a list of lists (len(list) should equal to K), which contains K elements. Each element is a list contains two parts, the first part contains the index of all training folds, e.g. Fold 2 to Fold 5 in split 1. The second part contains the index of validation fold, e.g. Fold 1 in  split 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(x_train, y_train, k=5):\n",
    "    n_samples = x_train.shape[0]\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    folds = []\n",
    "    size = n_samples//k + 1\n",
    "    for i in range(n_samples % k):\n",
    "        start = i * size\n",
    "        fold = indices[start:start+size]\n",
    "        folds.append(fold)\n",
    "    size = n_samples // k\n",
    "    for i in range(n_samples % k, k):\n",
    "        start = i * size\n",
    "        fold = indices[start:start+size]\n",
    "        folds.append(fold)\n",
    "    folds = np.asarray(folds)\n",
    "    kfold = []\n",
    "    for i in range(k):\n",
    "        train = folds[np.arange(k) != i]\n",
    "        val = folds[i]\n",
    "        kfold.append([train.ravel(), val])\n",
    "    return kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_data = cross_validation(x_train, y_train, k=10)\n",
    "assert len(kfold_data) == 10  # should contain 10 fold of data\n",
    "assert len(kfold_data[0]) == 2  # each element should contain train fold and validation fold\n",
    "assert kfold_data[0][1].shape[0] == 55  # The number of data in each validation fold should equal to training data divieded by K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Using sklearn.svm.SVC to train a classifier on the provided train set and conduct the grid search of “C” and “gamma” to find the best parameters by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mse(y_pred, y_test):\n",
    "    return np.sum((y_pred-y_test)**2) / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_gridsearch(x, y, kfold, cand_C, cand_gamma, is_regression=False):\n",
    "    gridsearch = []\n",
    "    max_acc, min_mse = 0, 1e10\n",
    "    best_C, best_gamma = 0, 0\n",
    "    for C in cand_C:\n",
    "        t = []\n",
    "        for gamma in cand_gamma:\n",
    "            if is_regression:\n",
    "                avg_mse = 0\n",
    "                for f in kfold:\n",
    "                    clf = SVR(C=C, kernel='rbf', gamma=gamma)\n",
    "                    clf.fit(x[f[0]], y[f[0]])\n",
    "                    y_pred = clf.predict(x[f[1]])\n",
    "                    mse = cal_mse(y_pred, y[f[1]])\n",
    "                    avg_mse += mse\n",
    "                avg_mse /= len(kfold)\n",
    "                print(f'C={C}, gamma={gamma}, avg mse={avg_mse:.2f}')\n",
    "                t.append(avg_mse)\n",
    "                if avg_mse <= min_mse:\n",
    "                    best_C = C\n",
    "                    best_gamma = gamma\n",
    "                    min_mse = avg_mse\n",
    "            else:\n",
    "                avg_acc = 0\n",
    "                for f in kfold:\n",
    "                    clf = SVC(C=C, kernel='rbf', gamma=gamma)\n",
    "                    clf.fit(x[f[0]], y[f[0]])\n",
    "                    y_pred = clf.predict(x[f[1]])\n",
    "                    acc = accuracy_score(y_pred, y[f[1]])\n",
    "                    avg_acc += np.around(acc, 2)\n",
    "                avg_acc /= len(kfold)\n",
    "                print(f'C={C}, gamma={gamma}, avg acc={avg_acc:.2f}')\n",
    "                t.append(avg_acc)\n",
    "                if avg_acc >= max_acc:\n",
    "                    best_C = C\n",
    "                    best_gamma = gamma\n",
    "                    max_acc = avg_acc\n",
    "        gridsearch.append(t)\n",
    "    gridsearch = np.asarray(gridsearch)\n",
    "    return gridsearch, (best_C, best_gamma, max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01, gamma=0.0001, avg acc=0.69\n",
      "C=0.01, gamma=0.001, avg acc=0.69\n",
      "C=0.01, gamma=0.01, avg acc=0.69\n",
      "C=0.01, gamma=0.1, avg acc=0.69\n",
      "C=0.01, gamma=1, avg acc=0.69\n",
      "C=0.01, gamma=10, avg acc=0.69\n",
      "C=0.01, gamma=100, avg acc=0.69\n",
      "C=0.01, gamma=1000, avg acc=0.69\n",
      "C=0.1, gamma=0.0001, avg acc=0.69\n",
      "C=0.1, gamma=0.001, avg acc=0.69\n",
      "C=0.1, gamma=0.01, avg acc=0.69\n",
      "C=0.1, gamma=0.1, avg acc=0.69\n",
      "C=0.1, gamma=1, avg acc=0.69\n",
      "C=0.1, gamma=10, avg acc=0.69\n",
      "C=0.1, gamma=100, avg acc=0.69\n",
      "C=0.1, gamma=1000, avg acc=0.69\n",
      "C=1, gamma=0.0001, avg acc=0.69\n",
      "C=1, gamma=0.001, avg acc=0.69\n",
      "C=1, gamma=0.01, avg acc=0.69\n",
      "C=1, gamma=0.1, avg acc=0.69\n",
      "C=1, gamma=1, avg acc=0.69\n",
      "C=1, gamma=10, avg acc=0.69\n",
      "C=1, gamma=100, avg acc=0.69\n",
      "C=1, gamma=1000, avg acc=0.69\n",
      "C=10, gamma=0.0001, avg acc=0.76\n",
      "C=10, gamma=0.001, avg acc=0.89\n",
      "C=10, gamma=0.01, avg acc=0.69\n",
      "C=10, gamma=0.1, avg acc=0.69\n",
      "C=10, gamma=1, avg acc=0.69\n",
      "C=10, gamma=10, avg acc=0.69\n",
      "C=10, gamma=100, avg acc=0.69\n",
      "C=10, gamma=1000, avg acc=0.69\n",
      "C=100, gamma=0.0001, avg acc=0.89\n",
      "C=100, gamma=0.001, avg acc=0.89\n",
      "C=100, gamma=0.01, avg acc=0.69\n",
      "C=100, gamma=0.1, avg acc=0.69\n",
      "C=100, gamma=1, avg acc=0.69\n",
      "C=100, gamma=10, avg acc=0.69\n",
      "C=100, gamma=100, avg acc=0.69\n",
      "C=100, gamma=1000, avg acc=0.69\n",
      "C=1000, gamma=0.0001, avg acc=0.89\n",
      "C=1000, gamma=0.001, avg acc=0.89\n",
      "C=1000, gamma=0.01, avg acc=0.69\n",
      "C=1000, gamma=0.1, avg acc=0.69\n",
      "C=1000, gamma=1, avg acc=0.69\n",
      "C=1000, gamma=10, avg acc=0.69\n",
      "C=1000, gamma=100, avg acc=0.69\n",
      "C=1000, gamma=1000, avg acc=0.69\n",
      "C=10000, gamma=0.0001, avg acc=0.89\n",
      "C=10000, gamma=0.001, avg acc=0.89\n",
      "C=10000, gamma=0.01, avg acc=0.69\n",
      "C=10000, gamma=0.1, avg acc=0.69\n",
      "C=10000, gamma=1, avg acc=0.69\n",
      "C=10000, gamma=10, avg acc=0.69\n",
      "C=10000, gamma=100, avg acc=0.69\n",
      "C=10000, gamma=1000, avg acc=0.69\n",
      "Best parameter (C, gamma): (10000, 0.001, 0.893)\n"
     ]
    }
   ],
   "source": [
    "cand_C = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "cand_gamma = [1e-4, 1e-3, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "gridsearch, best_parameters = svm_gridsearch(x_train, y_train, kfold_data, cand_C, cand_gamma)\n",
    "print(f'Best parameter (C, gamma): {best_parameters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Plot the grid search results of your SVM. The x, y represents the hyperparameters of “gamma” and “C”, respectively. And the color represents the average score of validation folds\n",
    "You reults should be look like this reference image below ![image](https://miro.medium.com/max/1296/1*wGWTup9r4cVytB5MOnsjdQ.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_heatmap(im, valfmt, threshold=None):\n",
    "    data = im.get_array()\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    texts = []\n",
    "    textcolors = ['black', 'white']\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_heatmap(im, valfmt, threshold=None):\n",
    "    data = im.get_array()\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    texts = []\n",
    "    textcolors = ['black', 'white']\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None, **kwargs):\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    plt.setp(\n",
    "        ax.get_yticklabels(), rotation=90,\n",
    "        va='bottom', ha='center', rotation_mode='anchor')\n",
    "    ax.set_xlabel('Gamma Parameter')\n",
    "    ax.set_ylabel('C Parameter')\n",
    "    ax.tick_params(top=False, bottom=True, labeltop=False, labelbottom=True)\n",
    "    return im, cbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im, cbar = heatmap(gridsearch, cand_C, cand_gamma, ax=ax, cmap='seismic_r')\n",
    "texts = annotate_heatmap(im, valfmt='{x:.2f}', threshold=0.2)\n",
    "plt.title('Hyperparameter Gridsearch')\n",
    "fig.tight_layout()\n",
    "plt.savefig('gridsearch_svc.png', dpi=300, transparent=True)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Train your SVM model by the best parameters you found from question 2 on the whole training set and evaluate the performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10, gamma=0.001, avg acc=0.90\n",
      "C=10, gamma=0.0012, avg acc=0.90\n",
      "C=10, gamma=0.0014, avg acc=0.90\n",
      "C=10, gamma=0.0016, avg acc=0.90\n",
      "C=10, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=10.5, gamma=0.001, avg acc=0.90\n",
      "C=10.5, gamma=0.0012, avg acc=0.90\n",
      "C=10.5, gamma=0.0014, avg acc=0.90\n",
      "C=10.5, gamma=0.0016, avg acc=0.90\n",
      "C=10.5, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=11, gamma=0.001, avg acc=0.90\n",
      "C=11, gamma=0.0012, avg acc=0.90\n",
      "C=11, gamma=0.0014, avg acc=0.90\n",
      "C=11, gamma=0.0016, avg acc=0.90\n",
      "C=11, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=12, gamma=0.001, avg acc=0.90\n",
      "C=12, gamma=0.0012, avg acc=0.90\n",
      "C=12, gamma=0.0014, avg acc=0.90\n",
      "C=12, gamma=0.0016, avg acc=0.90\n",
      "C=12, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=13, gamma=0.001, avg acc=0.90\n",
      "C=13, gamma=0.0012, avg acc=0.90\n",
      "C=13, gamma=0.0014, avg acc=0.90\n",
      "C=13, gamma=0.0016, avg acc=0.90\n",
      "C=13, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=14, gamma=0.001, avg acc=0.90\n",
      "C=14, gamma=0.0012, avg acc=0.90\n",
      "C=14, gamma=0.0014, avg acc=0.90\n",
      "C=14, gamma=0.0016, avg acc=0.90\n",
      "C=14, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=15, gamma=0.001, avg acc=0.90\n",
      "C=15, gamma=0.0012, avg acc=0.90\n",
      "C=15, gamma=0.0014, avg acc=0.90\n",
      "C=15, gamma=0.0016, avg acc=0.90\n",
      "C=15, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=16, gamma=0.001, avg acc=0.90\n",
      "C=16, gamma=0.0012, avg acc=0.90\n",
      "C=16, gamma=0.0014, avg acc=0.90\n",
      "C=16, gamma=0.0016, avg acc=0.90\n",
      "C=16, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=17, gamma=0.001, avg acc=0.90\n",
      "C=17, gamma=0.0012, avg acc=0.90\n",
      "C=17, gamma=0.0014, avg acc=0.90\n",
      "C=17, gamma=0.0016, avg acc=0.90\n",
      "C=17, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=18, gamma=0.001, avg acc=0.90\n",
      "C=18, gamma=0.0012, avg acc=0.90\n",
      "C=18, gamma=0.0014, avg acc=0.90\n",
      "C=18, gamma=0.0016, avg acc=0.90\n",
      "C=18, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=19, gamma=0.001, avg acc=0.90\n",
      "C=19, gamma=0.0012, avg acc=0.90\n",
      "C=19, gamma=0.0014, avg acc=0.90\n",
      "C=19, gamma=0.0016, avg acc=0.90\n",
      "C=19, gamma=0.0018000000000000002, avg acc=0.89\n",
      "C=20, gamma=0.001, avg acc=0.90\n",
      "C=20, gamma=0.0012, avg acc=0.90\n",
      "C=20, gamma=0.0014, avg acc=0.90\n",
      "C=20, gamma=0.0016, avg acc=0.90\n",
      "C=20, gamma=0.0018000000000000002, avg acc=0.89\n",
      "Best parameter (C, gamma): (20, 0.0014, 0.9018181818181813)\n"
     ]
    }
   ],
   "source": [
    "kfold_data = cross_validation(x_train, y_train, k=55)\n",
    "cand_C = [10, 10.5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "cand_gamma = [1e-3, 1.2*1e-3, 1.4*1e-3, 1.6*1e-3, 1.8*1e-3]\n",
    "gridsearch, best_parameters = svm_gridsearch(x_train, y_train, kfold_data, cand_C, cand_gamma)\n",
    "print(f'Best parameter (C, gamma): {best_parameters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.90625\n"
     ]
    }
   ],
   "source": [
    "best_C, best_gamma, _ = best_parameters\n",
    "best_model = SVC(C=best_C, kernel='rbf', gamma=best_gamma)\n",
    "best_model.fit(x_train, y_train)\n",
    "y_pred = best_model.predict(x_test)\n",
    "print(\"Accuracy score: \", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
